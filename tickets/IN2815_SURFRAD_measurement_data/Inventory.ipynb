{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a01519-0258-4a35-9cff-7f0c3b8a7c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,str(Path(os.path.abspath('.')).parent.parent))\n",
    "import library.validation.parsing as parsing\n",
    "import library.validation.SOLRAD.inventory as inventorying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "657e0aca-1b13-41a0-bf9c-49d83ccc931c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ticket_path_sur = \"/home/lhn3e/OneDrive-3E/Research/Solar/tickets/2023/IN2815_SURFRAD_measurement_data\"\n",
    "meta_path_sur =  os.path.join(ticket_path_sur, 'metadata')\n",
    "final_path_sur =  os.path.join(ticket_path_sur, 'final_data')\n",
    "yaml_path = Path.home()/\"OneDrive-3E/Research/Solar/tickets/2023/IN2983_final_parsing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f0cfff-0f14-4a73-8156-396afc9b05ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(yaml_path, 'providers.yml'), 'r') as file:\n",
    "    site_info = yaml.safe_load(file)\n",
    "    \n",
    "# Extract information\n",
    "surfrad_info = site_info.get('surfrad', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf4f035-e514-4f98-b971-c0bc49064b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(meta_path_sur, 'data.csv'))\n",
    "metadata['station name'] = metadata['station name'].apply(parsing.normalize_station_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7820c38f-8c8f-4be9-9d5d-42ee1c16aac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(final_path_sur):\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(final_path_sur, file_name), index_col = 0)\n",
    "        variable = df.columns\n",
    "\n",
    "        # from metadata\n",
    "        site_name, latitude, longitude = inventorying.extract_from_metadata(file_name, metadata)\n",
    "\n",
    "            \n",
    "        # from final_data\n",
    "        start_times, end_times, completenesses, device_type, pyranometer_types, parameter_ids, timedelta_obj = inventorying.extract_from_final_data(df)\n",
    "\n",
    "        \n",
    "        # from yaml file\n",
    "        source, domain, classification, unit, temporal_aggregation_method, temporal_aggregation_convention = inventorying.extract_from_yaml_file(surfrad_info, df)\n",
    "        \n",
    "        \n",
    "        # Create a row for the inventory\n",
    "        row = pd.DataFrame({\n",
    "            'name': [site_name] * len(variable),\n",
    "            'domain': domain,\n",
    "            'latitude': [latitude] * len(variable),\n",
    "            'longitude': [longitude] * len(variable),\n",
    "            'source': source,\n",
    "            'classification': classification,\n",
    "            'device_type': device_type,\n",
    "            'pyranometer_type': pyranometer_types,\n",
    "            'variable_name': variable,\n",
    "            'variable_physical_parameter_id': parameter_ids,\n",
    "            'variable_units': unit,\n",
    "            'variable_time_granularity': [timedelta_obj] * len(variable),\n",
    "            'variable_start': start_times,\n",
    "            'variable_end': end_times,\n",
    "            'variable_temporal_aggregation_method': temporal_aggregation_method,\n",
    "            'variable_temporal_aggregation_period': [timedelta_obj] * len(variable),\n",
    "            'variable_temporal_aggregation_convention': temporal_aggregation_convention,\n",
    "            'variable_data_availability_percent': completenesses,\n",
    "            'timeseries_path': os.path.join(final_path_sur, file_name)\n",
    "        })\n",
    "\n",
    "        # Concatenate to the inventory dataframe\n",
    "        inventory = pd.concat([inventory, row], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60dc659-f394-429e-8c19-595069dfba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory.to_csv(os.path.join(ticket_path_sur, 'inventory.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhn_internship",
   "language": "python",
   "name": "lhn_internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
