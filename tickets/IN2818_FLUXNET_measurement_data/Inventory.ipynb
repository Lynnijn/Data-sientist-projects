{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb43f6e-4b9f-4f90-bf7e-8e646c8eac21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,str(Path(os.path.abspath('.')).parent.parent))\n",
    "import library.validation.parsing as parsing\n",
    "import library.validation.FLUXNET.inventory as inventorying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e23d84-cf84-42f6-a3c2-8da1b520bbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ticket_path_flu = Path.home()/\"OneDrive-3E/Research/Solar/tickets/2023/IN2818_FLUXNET_measurement_data\"\n",
    "final_path_flu =  os.path.join(ticket_path_flu, 'final_data')\n",
    "meta_path_flu =  os.path.join(ticket_path_flu, 'metadata')\n",
    "yaml_path = Path.home()/\"OneDrive-3E/Research/Solar/tickets/2023/IN2983_final_parsing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4bc54c-81ca-49c6-afc5-109eb8ee4b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(yaml_path, 'providers.yml'), 'r') as file:\n",
    "    site_info = yaml.safe_load(file)\n",
    "    \n",
    "solrad_info = site_info.get('fluxnet', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1dfa2c-2db1-4972-9b45-b937916aefa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(meta_path_flu, 'data.csv'))\n",
    "metadata['station_name'] = metadata['station_name'].apply(parsing.normalize_station_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28e5725-84c4-4600-afba-2efddb21907e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(final_path_flu):\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(final_path_flu, file_name), index_col = 0)\n",
    "        variable = df.columns\n",
    "\n",
    "        # from metadata\n",
    "        site_name, latitude, longitude = inventorying.extract_from_metadata(file_name, metadata)\n",
    "\n",
    "            \n",
    "        # from final_data\n",
    "        start_times, end_times, completenesses, pyrnanometer_types, parameter_ids, timedelta_obj = inventorying.extract_from_final_data(df)\n",
    "\n",
    "        \n",
    "        # from yaml file\n",
    "        source, domain, classification, device_type, unit, temporal_aggregation_method, temporal_aggregation_convention = inventorying.extract_from_yaml_file(solrad_info, df)\n",
    "        \n",
    "        \n",
    "        # Create a row for the inventory\n",
    "        row = pd.DataFrame({\n",
    "            'name': [site_name] * len(variable),\n",
    "            'domain': domain,\n",
    "            'latitude': [latitude] * len(variable),\n",
    "            'longitude': [longitude] * len(variable),\n",
    "            'source': source,\n",
    "            'classification': classification,\n",
    "            'device_type': device_type,\n",
    "            'pyrnanometer_type': pyrnanometer_types,\n",
    "            'variable_name': variable,\n",
    "            'variable_physical_parameter_id': parameter_ids,\n",
    "            'variable_units': unit,\n",
    "            'variable_time_granularity': [timedelta_obj] * len(variable),\n",
    "            'variable_start': start_times,\n",
    "            'variable_end': end_times,\n",
    "            'variable_temporal_aggregation_method': temporal_aggregation_method,\n",
    "            'variable_temporal_aggregation_period': [timedelta_obj] * len(variable),\n",
    "            'variable_temporal_aggregation_convention': temporal_aggregation_convention,\n",
    "            'variable_data_availability_percent': completenesses,\n",
    "            'timeseries_path': os.path.join(final_path_flu, file_name)\n",
    "        })\n",
    "\n",
    "        # Concatenate to the inventory dataframe\n",
    "        inventory = pd.concat([inventory, row], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a673460-6545-49f3-9a55-7d2a9c3d66f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory.to_csv(os.path.join(ticket_path_flu, 'inventory.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhn_internship",
   "language": "python",
   "name": "lhn_internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
