{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b1508b-9c44-4f6f-96ac-b3aa736edeb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0,str(Path(os.path.abspath('.')).parent.parent))\n",
    "import library.validation.parsing as parsing\n",
    "import library.validation.SoRMS.inventory as inventorying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a104992-b54e-4d87-8604-ee87b6f3bf09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ticket_path_rms = Path.home()/\"OneDrive-3E/Research/Solar/tickets/2023/IN2866_SoRMS_measurement_data\"\n",
    "final_path_rms =  os.path.join(ticket_path_rms, 'final_data')\n",
    "meta_path_rms =  os.path.join(ticket_path_rms, 'metadata')\n",
    "yaml_path = Path.home()/\"OneDrive-3E/Research/Solar/tickets/2023/IN2983_final_parsing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b770ba76-25a3-4f69-8a2d-8d3454b1f650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(yaml_path, 'providers.yml'), 'r') as file:\n",
    "    site_info = yaml.safe_load(file)\n",
    "    \n",
    "# Extract information\n",
    "solrad_info = site_info.get('sorms', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f85c850-4292-4a6b-8e6e-b24cf56f3c59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(meta_path_rms, 'data.csv'))\n",
    "metadata['normalized station name'] = metadata['station name'].apply(parsing.normalize_station_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef22252c-c2da-4bf1-b095-7b97b14c3411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory = pd.DataFrame()\n",
    "\n",
    "for file_name in os.listdir(final_path_rms):\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(final_path_rms, file_name), index_col = 0)\n",
    "        variable = df.columns\n",
    "        site_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "        # from metadata\n",
    "        latitude, longitude = inventorying.extract_from_metadata(site_name, metadata)\n",
    "\n",
    "            \n",
    "        # from final_data\n",
    "        start_times, end_times, completenesses, parameter_ids, timedelta_obj = inventorying.extract_from_final_data(df)\n",
    "\n",
    "        \n",
    "        # from yaml file\n",
    "        source, domain, classification, unit, temporal_aggregation_method, temporal_aggregation_convention = inventorying.extract_from_yaml_file(solrad_info, df)\n",
    "        \n",
    "              \n",
    "        \n",
    "        # Create a row for the inventory\n",
    "        row = pd.DataFrame({\n",
    "            'name': [site_name] * len(variable),\n",
    "            'domain': domain,\n",
    "            'latitude': [latitude] * len(variable),\n",
    "            'longitude': [longitude] * len(variable),\n",
    "            'source': source,\n",
    "            'classification': classification,\n",
    "            'device_type': 'pyronometer',\n",
    "            'pyranometer_type': '',\n",
    "            'variable_name': variable,\n",
    "            'variable_physical_parameter_id': parameter_ids,\n",
    "            'variable_units': unit,\n",
    "            'variable_time_granularity': [timedelta_obj] * len(variable),\n",
    "            'variable_start': start_times,\n",
    "            'variable_end': end_times,\n",
    "            'variable_temporal_aggregation_method': temporal_aggregation_method,\n",
    "            'variable_temporal_aggregation_period': [timedelta_obj] * len(variable),\n",
    "            'variable_temporal_aggregation_convention': temporal_aggregation_convention,\n",
    "            'variable_data_availability_percent': completenesses,\n",
    "            'timeseries_path': os.path.join(final_path_rms, file_name)\n",
    "        })\n",
    "\n",
    "        # Concatenate to the inventory dataframe\n",
    "        inventory = pd.concat([inventory, row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e988851-f4a4-4325-88f2-bd29dba5f617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory['device_type'] = inventory.apply(lambda row: inventorying.get_device(row['name'], row['variable_name']) if row['variable_name'] else None, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bcca7fc-6a76-4ead-94c6-448da801d9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory['pyranometer_type'] = inventory.apply(lambda row: inventorying.get_pyranometer(row['name'], row['variable_name']) if row['variable_name'] else None, axis=1)\n",
    "inventory['pyranometer_type'].replace({None: ''}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e06255-f7ba-4ba4-bbc7-cb57d7d3f770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inventory.to_csv(os.path.join(ticket_path_rms, 'inventory.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b698f-7125-423f-8eee-7ea9725222df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhn_internship",
   "language": "python",
   "name": "lhn_internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
